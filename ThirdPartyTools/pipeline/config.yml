pipeline:
  name: pyannote.audio.pipeline.speaker_diarization.SpeakerDiarization
  params:
    # replace {{EXP_DIR}} by its actual value
    sad_scores: /projectnb2/ece601/A2-Team6/gilbert_folder/EC601-A2Team6-MultiSpeakerIdentification/ThirdPartyTools/sad/train/VoxConverse.SpeakerDiarization.voxconverse.train/validate_detection_fscore/VoxConverse.SpeakerDiarization.voxconverse.development/apply/0120/
    scd_scores: /projectnb2/ece601/A2-Team6/gilbert_folder/EC601-A2Team6-MultiSpeakerIdentification/ThirdPartyTools/scd/train/VoxConverse.SpeakerDiarization.voxconverse.train/validate_segmentation_fscore/VoxConverse.SpeakerDiarization.voxconverse.development/apply/0110/
    embedding: /projectnb2/ece601/A2-Team6/gilbert_folder/EC601-A2Team6-MultiSpeakerIdentification/ThirdPartyTools/emb_pretrained/emb_ami
    method: affinity_propagation

# one can freeze some of the hyper-parameters
# for instance, in this example, we are using
# hyper-parameters obtained in the speech 
# actitivy detection pipeline tutorial
freeze:
  speech_turn_segmentation:
    speech_activity_detection:
      min_duration_off: 0.1
      min_duration_on: 0.1
      offset: 0.5151751798551264
      onset: 0.5151751798551264
      pad_offset: 0.0
      pad_onset: 0.0
